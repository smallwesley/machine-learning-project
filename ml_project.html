<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Wesley Small (smallwesley)" />


<title>ML Predictions of Weight Lifting Exercises (Via Wearables)</title>

<script src="ml_project_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="ml_project_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="ml_project_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="ml_project_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="ml_project_files/bootstrap-3.3.5/shim/respond.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="ml_project_files/highlight/default.css"
      type="text/css" />
<script src="ml_project_files/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="ml_project_files/navigation-1.1/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="fluid-row" id="header">



<h1 class="title toc-ignore">ML Predictions of Weight Lifting Exercises (Via Wearables)</h1>
<h4 class="author"><em>Wesley Small (smallwesley)</em></h4>
<h4 class="date"><em>July 9, 2016</em></h4>

</div>


<div id="executive-summary" class="section level2">
<h2>Executive Summary</h2>
<p>This purpose of this report is examine machine learning model selection (+ cross validation training), with the goal to conduct a series of exercise predictions given a dataset activity accelerometer recordings.</p>
<p>This report will have the following sections:</p>
<ol style="list-style-type: decimal">
<li><a href="#background">Background</a></li>
<li><a href="#exploratory-analysis">Exploratory Analysis</a></li>
<li><a href="#environmental-setup">Environment Setup</a></li>
<li><a href="#tidy-data-phase">Tidy Data Phase</a></li>
<li><a href="#preprocessing">Preprocessing</a></li>
<li><a href="#model-selection">Model Selection</a></li>
<li><a href="#model-choice">Model Choice</a></li>
<li><a href="#quiz-dataset-predictions">Quiz Dataset Predictions</a></li>
</ol>
</div>
<div id="background" class="section level2">
<h2>Background</h2>
<p>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement – a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.</p>
<p>The data collection is from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.</p>
<p>Details about the dataset and the manner it was collected can be found here. <a href="http://groupware.les.inf.puc-rio.br/har" class="uri">http://groupware.les.inf.puc-rio.br/har</a></p>
<p>See the section on the Weight Lifting Exercise Dataset.</p>
<p>A special thank you to original source of this dataset: Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human ’13) . Stuttgart, Germany: ACM SIGCHI, 2013.</p>
</div>
<div id="environment-setup" class="section level2">
<h2>Environment Setup</h2>
<p>This method assists in loading up libraries and installing them if necessary.</p>
<pre class="r"><code>usePackage&lt;-function(p){
  # load a package if installed, else load after installation.
  # Args: p: package name in quotes
  if (!is.element(p, installed.packages()[,1])){
    print(paste(&#39;Package:&#39;,p,&#39;Not found, Installing Now...&#39;))
    suppressMessages(install.packages(p, dep = TRUE))}
  print(paste(&#39;Loading Package :&#39;,p))
  suppressMessages(require(p, character.only = TRUE))
}

usePackage(&quot;caret&quot;)</code></pre>
<pre><code>## [1] &quot;Loading Package : caret&quot;</code></pre>
<pre class="r"><code>usePackage(&quot;ggplot2&quot;)</code></pre>
<pre><code>## [1] &quot;Loading Package : ggplot2&quot;</code></pre>
<pre class="r"><code>usePackage(&quot;rattle&quot;)</code></pre>
<pre><code>## [1] &quot;Loading Package : rattle&quot;</code></pre>
<pre><code>## Warning: Failed to load RGtk2 dynamic library, attempting to install it.</code></pre>
<pre class="r"><code>usePackage(&quot;randomForest&quot;)</code></pre>
<pre><code>## [1] &quot;Loading Package : randomForest&quot;</code></pre>
<pre class="r"><code>usePackage(&quot;rpart&quot;)</code></pre>
<pre><code>## [1] &quot;Loading Package : rpart&quot;</code></pre>
<pre class="r"><code>usePackage(&quot;e1071&quot;)</code></pre>
<pre><code>## [1] &quot;Loading Package : e1071&quot;</code></pre>
</div>
<div id="exploratory-analysis" class="section level2">
<h2>Exploratory Analysis</h2>
<p>This section will initial examine the datasets on the accelerometers. In order to reproduce all steps in this report, please pay attention to a few items necessary to prepare a proper working environment for your workstation.</p>
<pre class="r"><code># SET WORKING DIRECTORY
setwd(&quot;/Users/smallwes/develop/academic/coursera/datascience/c8-ml/project1/&quot;)</code></pre>
<p><strong>NOTE</strong>: <em>Please change this according to your directory system if you obtain these file from github</em></p>
<p>File names in question:</p>
<pre class="r"><code>trainingFilename &lt;- &quot;pml-training.csv&quot; 
trainingFileUrl &lt;- &quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&quot;
# Note: this training file will be used for model selection + split to training/testing partitions.

testingFilename &lt;- &quot;pml-testing.csv&quot;
testingFileUrl &lt;- &quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv&quot;
# Note: this testing file will be used post model selection and specifically for solving the quiz predictions.</code></pre>
<p>Read datasets:</p>
<pre class="r"><code>trainingDataset    &lt;- read.csv( url(trainingFileUrl), header=TRUE )
quizTestingDataset &lt;- read.csv( url(testingFileUrl),  header=TRUE)</code></pre>
<p>Here is an initial set of summaries about the datasets. Due to the verbose nature, some of the actions below are commented as they display redundant information in different shapes.</p>
<pre class="r"><code>dim(trainingDataset)</code></pre>
<pre><code>## [1] 19622   160</code></pre>
<pre class="r"><code>dim(quizTestingDataset)</code></pre>
<pre><code>## [1]  20 160</code></pre>
<pre class="r"><code>#View(trainingDataset)
str(trainingDataset, 1:20)</code></pre>
<pre><code>## &#39;data.frame&#39;:    19622 obs. of  160 variables:
##  $ X                       : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ user_name               : Factor w/ 6 levels &quot;adelmo&quot;,&quot;carlitos&quot;,..: 2 2 2 2 2 2 2 2 2 2 ...
##  $ raw_timestamp_part_1    : int  1323084231 1323084231 1323084231 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 ...
##  $ raw_timestamp_part_2    : int  788290 808298 820366 120339 196328 304277 368296 440390 484323 484434 ...
##  $ cvtd_timestamp          : Factor w/ 20 levels &quot;02/12/2011 13:32&quot;,..: 9 9 9 9 9 9 9 9 9 9 ...
##  $ new_window              : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ num_window              : int  11 11 11 12 12 12 12 12 12 12 ...
##  $ roll_belt               : num  1.41 1.41 1.42 1.48 1.48 1.45 1.42 1.42 1.43 1.45 ...
##  $ pitch_belt              : num  8.07 8.07 8.07 8.05 8.07 8.06 8.09 8.13 8.16 8.17 ...
##  $ yaw_belt                : num  -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 ...
##  $ total_accel_belt        : int  3 3 3 3 3 3 3 3 3 3 ...
##  $ kurtosis_roll_belt      : Factor w/ 397 levels &quot;&quot;,&quot;-0.016850&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_picth_belt     : Factor w/ 317 levels &quot;&quot;,&quot;-0.021887&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_yaw_belt       : Factor w/ 2 levels &quot;&quot;,&quot;#DIV/0!&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_roll_belt      : Factor w/ 395 levels &quot;&quot;,&quot;-0.003095&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_roll_belt.1    : Factor w/ 338 levels &quot;&quot;,&quot;-0.005928&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_yaw_belt       : Factor w/ 2 levels &quot;&quot;,&quot;#DIV/0!&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ max_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_picth_belt          : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_yaw_belt            : Factor w/ 68 levels &quot;&quot;,&quot;-0.1&quot;,&quot;-0.2&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ min_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_pitch_belt          : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_yaw_belt            : Factor w/ 68 levels &quot;&quot;,&quot;-0.1&quot;,&quot;-0.2&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ amplitude_roll_belt     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_pitch_belt    : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_yaw_belt      : Factor w/ 4 levels &quot;&quot;,&quot;#DIV/0!&quot;,&quot;0.00&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ var_total_accel_belt    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_roll_belt        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_pitch_belt          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_pitch_belt       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_pitch_belt          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_yaw_belt         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ gyros_belt_x            : num  0 0.02 0 0.02 0.02 0.02 0.02 0.02 0.02 0.03 ...
##  $ gyros_belt_y            : num  0 0 0 0 0.02 0 0 0 0 0 ...
##  $ gyros_belt_z            : num  -0.02 -0.02 -0.02 -0.03 -0.02 -0.02 -0.02 -0.02 -0.02 0 ...
##  $ accel_belt_x            : int  -21 -22 -20 -22 -21 -21 -22 -22 -20 -21 ...
##  $ accel_belt_y            : int  4 4 5 3 2 4 3 4 2 4 ...
##  $ accel_belt_z            : int  22 22 23 21 24 21 21 21 24 22 ...
##  $ magnet_belt_x           : int  -3 -7 -2 -6 -6 0 -4 -2 1 -3 ...
##  $ magnet_belt_y           : int  599 608 600 604 600 603 599 603 602 609 ...
##  $ magnet_belt_z           : int  -313 -311 -305 -310 -302 -312 -311 -313 -312 -308 ...
##  $ roll_arm                : num  -128 -128 -128 -128 -128 -128 -128 -128 -128 -128 ...
##  $ pitch_arm               : num  22.5 22.5 22.5 22.1 22.1 22 21.9 21.8 21.7 21.6 ...
##  $ yaw_arm                 : num  -161 -161 -161 -161 -161 -161 -161 -161 -161 -161 ...
##  $ total_accel_arm         : int  34 34 34 34 34 34 34 34 34 34 ...
##  $ var_accel_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_roll_arm         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_pitch_arm        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_yaw_arm             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_yaw_arm          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_yaw_arm             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ gyros_arm_x             : num  0 0.02 0.02 0.02 0 0.02 0 0.02 0.02 0.02 ...
##  $ gyros_arm_y             : num  0 -0.02 -0.02 -0.03 -0.03 -0.03 -0.03 -0.02 -0.03 -0.03 ...
##  $ gyros_arm_z             : num  -0.02 -0.02 -0.02 0.02 0 0 0 0 -0.02 -0.02 ...
##  $ accel_arm_x             : int  -288 -290 -289 -289 -289 -289 -289 -289 -288 -288 ...
##  $ accel_arm_y             : int  109 110 110 111 111 111 111 111 109 110 ...
##  $ accel_arm_z             : int  -123 -125 -126 -123 -123 -122 -125 -124 -122 -124 ...
##  $ magnet_arm_x            : int  -368 -369 -368 -372 -374 -369 -373 -372 -369 -376 ...
##  $ magnet_arm_y            : int  337 337 344 344 337 342 336 338 341 334 ...
##  $ magnet_arm_z            : int  516 513 513 512 506 513 509 510 518 516 ...
##  $ kurtosis_roll_arm       : Factor w/ 330 levels &quot;&quot;,&quot;-0.02438&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_picth_arm      : Factor w/ 328 levels &quot;&quot;,&quot;-0.00484&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_yaw_arm        : Factor w/ 395 levels &quot;&quot;,&quot;-0.01548&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_roll_arm       : Factor w/ 331 levels &quot;&quot;,&quot;-0.00051&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_pitch_arm      : Factor w/ 328 levels &quot;&quot;,&quot;-0.00184&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_yaw_arm        : Factor w/ 395 levels &quot;&quot;,&quot;-0.00311&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ max_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_picth_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_yaw_arm             : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_yaw_arm             : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_roll_arm      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_pitch_arm     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_yaw_arm       : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ roll_dumbbell           : num  13.1 13.1 12.9 13.4 13.4 ...
##  $ pitch_dumbbell          : num  -70.5 -70.6 -70.3 -70.4 -70.4 ...
##  $ yaw_dumbbell            : num  -84.9 -84.7 -85.1 -84.9 -84.9 ...
##  $ kurtosis_roll_dumbbell  : Factor w/ 398 levels &quot;&quot;,&quot;-0.0035&quot;,&quot;-0.0073&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_picth_dumbbell : Factor w/ 401 levels &quot;&quot;,&quot;-0.0163&quot;,&quot;-0.0233&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_yaw_dumbbell   : Factor w/ 2 levels &quot;&quot;,&quot;#DIV/0!&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_roll_dumbbell  : Factor w/ 401 levels &quot;&quot;,&quot;-0.0082&quot;,&quot;-0.0096&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_pitch_dumbbell : Factor w/ 402 levels &quot;&quot;,&quot;-0.0053&quot;,&quot;-0.0084&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_yaw_dumbbell   : Factor w/ 2 levels &quot;&quot;,&quot;#DIV/0!&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ max_roll_dumbbell       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_picth_dumbbell      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_yaw_dumbbell        : Factor w/ 73 levels &quot;&quot;,&quot;-0.1&quot;,&quot;-0.2&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ min_roll_dumbbell       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_pitch_dumbbell      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_yaw_dumbbell        : Factor w/ 73 levels &quot;&quot;,&quot;-0.1&quot;,&quot;-0.2&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ amplitude_roll_dumbbell : num  NA NA NA NA NA NA NA NA NA NA ...
##   [list output truncated]</code></pre>
<pre class="r"><code>#summary(trainingDataset)
#head(trainingDataset)
#str(quizTestingDataset)</code></pre>
<div id="summation-of-base-dataset-findings" class="section level4">
<h4>SUMMATION OF BASE DATASET FINDINGS:</h4>
<ol style="list-style-type: decimal">
<li>“classe” column is located at the end; column 153</li>
<li>Model creation sees us relating the outcome to “all other columns” using formula “classe ~ .”</li>
<li>However a significant number of fields have invalid data in numeric columns - standardize “NA” data upon reading of the csv file.</li>
<li>A tidy-data phase shall occur identically on both training and the quiz testing dataset before before we engage in model building (cross validation, prediction, and comparison of models)</li>
</ol>
</div>
</div>
<div id="tidy-data-phase" class="section level2">
<h2>Tidy Data Phase</h2>
<p>This Tidy Data section including the next Preprocessing phase shall attempt to reduce the dataset to the best set of clean predictors ( and covariates).</p>
<p>We will do the following: * Create dataframe with NA data specify na data: “NA”, blanks, and unknown numeric values “#DIV/0!” * Eliminate columns with no content including columns with NAs (i.e colmns max_roll_arm : num NA NA NA NA NA NA NA NA NA NA …) * Remove columns with non helpful model building info, i.e. X, username, new window, time columns as we’re not forecasting * Given the lectures notes from the ML course, we could look at preprocessing the data with imputting, eliminating near-zero values, etc.</p>
<pre class="r"><code># DEFINE EMPTY DATA SIGNATURES
naStringList = c(&quot;&quot;, &quot;NA&quot;,&quot;#DIV/0!&quot;)

# RELOAD WITH NA COLUMNS SETTING
modelDF &lt;- read.csv(url(trainingFileUrl), na.strings=naStringList, header=TRUE)

# SUBSET DF CLASS REQUIRED
classeColumn &lt;- modelDF$classe</code></pre>
<p>Initial report of the size of the training model dataset. We report on this a few times as we shrink the dataset based on a few techniquest.</p>
<pre class="r"><code>dim(modelDF)</code></pre>
<pre><code>## [1] 19622   160</code></pre>
<pre class="r"><code># REORDER COLUMNS ( MOVE CLASSE COLUMN TO START)
modelDF &lt;- modelDF[,c(ncol(modelDF),1:(ncol(modelDF)-1))]
colnames(modelDF)[1]</code></pre>
<pre><code>## [1] &quot;classe&quot;</code></pre>
<pre class="r"><code># EXPLICIT REMOVAL OF COLUMNS (NON HELPFUL; NOT NECESSARY FOR MODEL CREATION)
colnames(modelDF)[c(2:8)]</code></pre>
<pre><code>## [1] &quot;X&quot;                    &quot;user_name&quot;            &quot;raw_timestamp_part_1&quot;
## [4] &quot;raw_timestamp_part_2&quot; &quot;cvtd_timestamp&quot;       &quot;new_window&quot;          
## [7] &quot;num_window&quot;</code></pre>
<pre class="r"><code>modelDF &lt;- modelDF[,-c(2:8)]
dim(modelDF)</code></pre>
<pre><code>## [1] 19622   153</code></pre>
<pre class="r"><code># REMOVE COLUMN WITH NAs
# Review: http://stackoverflow.com/questions/2643939/remove-columns-from-dataframe-where-all-values-are-na
modelDF &lt;- modelDF[, unlist( lapply( modelDF, function(x) { !all(is.na(x) ) } ) ) ]
dim(modelDF)</code></pre>
<pre><code>## [1] 19622   147</code></pre>
<pre class="r"><code>getAnyNAColumnIndices &lt;- function(modelDF) {
 output &lt;- list(rep(FALSE, ncol(modelDF)))
 for (i in 1:ncol(modelDF)) {
   output[i] &lt;- (length( which(is.na(modelDF[,i]))) !=0)
 }
 unlist(output)
}
#getAnyNAColumnIndices(modelDF)
modelDF &lt;- modelDF[,!getAnyNAColumnIndices(modelDF)]
#str(modelDF)
dim(modelDF)</code></pre>
<pre><code>## [1] 19622    53</code></pre>
</div>
<div id="preprocessing" class="section level2">
<h2>Preprocessing</h2>
<p>Machine learning algorithms learn from data. It is critical that producing the right data for the problem we want to solve comes from tidy data techniques and this section of preprocess. The topics here were provide in machine learning lectures.</p>
<pre class="r"><code># REMOVING ZERO COVARIATES ( ML WK #2 LECTURE: COVARIATE CREATION )
nzvDF &lt;- nearZeroVar(modelDF, saveMetric=TRUE, names=TRUE)
isAnyNZV &lt;-any(nzvDF$nzv)
if (isAnyNZV) {
  modelDF &lt;- modelDF[, -nzvDF]
}
dim(modelDF)</code></pre>
<pre><code>## [1] 19622    53</code></pre>
<p><strong>NOTE:</strong> <em>There were no near zero covariates to remove as</em> <strong>isAnyNZV</strong> <em>equals</em> <strong>FALSE</strong></p>
<pre class="r"><code># REMOVE HIGHLY CORRELATED PREDICTORS ( ML WK #2 LECTURE: PREPROCESSION WITH PCA )
# Method obtained from: http://stackoverflow.com/questions/18275639/remove-highly-correlated-variables
corDF &lt;- cor(modelDF[,-1])
hc &lt;- findCorrelation(corDF, cutoff=0.8) #high correlated predictors matrix
hc &lt;- sort(hc)
modelDF &lt;- modelDF[,-c(hc + 1) ]
dim(modelDF)</code></pre>
<pre><code>## [1] 19622    40</code></pre>
<p><strong>For further notes about the setp taken in preparation of this report see the PROJECT PROTYPE WIP R FILE.</strong></p>
</div>
<div id="model-selection" class="section level2">
<h2>Model Selection</h2>
</div>
<div id="model-choice-cross-validation-subset-training-testing" class="section level1">
<h1>MODEL CHOICE: CROSS VALIDATION SUBSET TRAINING &amp; TESTING</h1>
<p>The training model dataset reduced from 153 columns to 40, is partitioned appropriately to perform cross validation.</p>
<pre class="r"><code>set.seed(1234)
inTrain = createDataPartition(modelDF$classe, p = 0.6, list=FALSE)
training = modelDF[ inTrain,]
testing = modelDF[-inTrain,]
dim(training)</code></pre>
<pre><code>## [1] 11776    40</code></pre>
<pre class="r"><code>dim(testing)</code></pre>
<pre><code>## [1] 7846   40</code></pre>
<div id="review-of-the-caret-library-features" class="section level4">
<h4>Review of the caret library features:</h4>
<pre class="r"><code>?train</code></pre>
<p>A few techniques about model seleciton were obtained after a review of the Caret library’s Train command &amp; TrainControl features found also in:</p>
<p><a href="http://topepo.github.io/caret/bytag.html" class="uri">http://topepo.github.io/caret/bytag.html</a></p>
</div>
<div id="the-formula" class="section level4">
<h4>The Formula</h4>
<p>Our primary formula used for all training of models is the following:</p>
<pre class="r"><code>paramFormula &lt;- classe ~ .</code></pre>
</div>
<div id="training-schemes" class="section level4">
<h4>Training schemes</h4>
<pre class="r"><code>paramControl &lt;- trainControl(
                    method = &quot;repeatedCV&quot;, number = 10, repeats = 5, 
                    returnResamp = &quot;all&quot;, classProbs = TRUE)

paramPreProcess &lt;- c(&quot;knnImpute&quot;, &quot;center&quot;,&quot;scale&quot;)</code></pre>
</div>
<div id="fit-predictive-models" class="section level4">
<h4>Fit Predictive Models:</h4>
<p>Build a series of models based on the formula ~, classe, ..</p>
<pre class="r"><code># TRAIN: RPART (using caret library&#39;s train)
set.seed(1234)
modelRpartA &lt;- train(classe ~ ., method=&quot;rpart&quot;, data=training, preProcess=paramPreProcess)</code></pre>
<pre class="r"><code># TRAIN: RPART (using rpart library)
set.seed(1234)
modelRpartB &lt;- rpart(paramFormula, data=training, method=&quot;class&quot;)  # Outcome y is factor A -&gt; E</code></pre>
<pre class="r"><code># TRAIN: SVM-RADICAL (using caret library&#39;s train)
#set.seed(1234)
#modelSvm &lt;- train(paramFormula, data=training, method=&quot;svmRadial&quot;)
# NOTE: DISABLED DUE TO MODEL TAKING TOO LONG TO GENERATE IN REPORT.</code></pre>
<pre class="r"><code># TRAIN: RF / RANDOM FOREST
#modelRF &lt;- train(paramFormula, method=&quot;rf&quot;, data=training, preProcess=paramPreprocess, 
#                 trControl=paramControl, prox=TRUE,allowParallel=TRUE)

# ABORTING this  training model using &quot;rf&quot; = reason taking too long to complete even with optimized settings.
# http://stats.stackexchange.com/questions/37370/random-forest-computing-time-in-r

# NOTE: Switching to an optimizaed &quot;random forest&quot; library.
modelRandomForests &lt;- randomForest(paramFormula, data=training,  proximity=TRUE, keep.forest=TRUE, importance=TRUE)</code></pre>
</div>
<div id="examine-r-part-model-fit-generated-from-carets-train" class="section level4">
<h4>Examine R-PART Model Fit generated from Caret’s Train</h4>
<p>Decision Tree using RPART from Caret’s Train Model Fit.</p>
<pre class="r"><code>fancyRpartPlot(modelRpartA$finalModel)</code></pre>
<p><img src="ml_project_files/figure-html/FANCY1-1.png" width="480" /></p>
</div>
<div id="examine-r-part-model-fit-generated-from-rpart-library" class="section level4">
<h4>Examine R-PART Model Fit generated from “RPart” Library</h4>
<pre class="r"><code>fancyRpartPlot(modelRpartB, palettes=c(&quot;Greys&quot;, &quot;Oranges&quot;))</code></pre>
<pre><code>## Warning: labs do not fit even at cex 0.15, there may be some overplotting</code></pre>
<p><img src="ml_project_files/figure-html/FANCY2-1.png" width="480" /></p>
</div>
<div id="examine-random-forest-model-fit" class="section level4">
<h4>Examine Random Forest Model Fit</h4>
<ol style="list-style-type: upper-alpha">
<li>The random forest model allows us to see the variable importance in a plot:</li>
</ol>
<pre class="r"><code>varImpPlot(modelRandomForests)</code></pre>
<p><img src="ml_project_files/figure-html/varImpPlot-1.png" width="480" /> B) Multi-dimensional Scaling Plot of a Proximity matrix within this Random Forest Model **Note:* <em>Created offline due to lengthy generation</em> <img src="MDSPLOT.jpg" alt="Multi-dimensional Scaling Plot" /></p>
</div>
<div id="model-fit-accuracy-comparison" class="section level4">
<h4>Model Fit Accuracy Comparison:</h4>
<p>A series of predctions are performed and we look at the cross-tabulation of observed &amp; predicted classes. These statistics include a accuracy marker which is one of the most useful statstics. For brevity, we’ll use this statistic primarily in choosing the best performing model.</p>
<pre class="r"><code>predRpartA &lt;- predict(modelRpartA, testing)
accuracyRpartA &lt;- confusionMatrix(predRpartA,testing$classe)$overall[&#39;Accuracy&#39;]

predRpartB &lt;- predict(modelRpartB, testing, type=&quot;class&quot;)
accuracyRpartB &lt;- confusionMatrix(predRpartB,testing$classe)$overall[&#39;Accuracy&#39;]

#DISABLED DUE TO MODEL CREATION TAKING LONG
#predSvm &lt;- predict(modelSvm, testing)
#accuracySvm &lt;- confusionMatrix(predSvm,testing$classe)$overall[&#39;Accuracy&#39;]

predRandomForests &lt;- predict(modelRandomForests, testing)
accuracyRandomForests &lt;- confusionMatrix(predRandomForests,testing$classe)$overall[&#39;Accuracy&#39;]</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">#</th>
<th align="left">MODEL FIT</th>
<th align="left">ACCURACY</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">RPART A</td>
<td align="left">0.4924802</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">RPART B</td>
<td align="left">0.6921998</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">SVM RADIAL</td>
<td align="left">0.91 (Approx)</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">RANDOM FOREST</td>
<td align="left">0.9909508</td>
</tr>
</tbody>
</table>
</div>
<div id="model-choice" class="section level2">
<h2>Model Choice</h2>
<p>The best performing model fit is provided to use from RandomForest library. It contains an accuracy of <strong>0.9909508</strong>, as provided as one of the more influencing statistics within the confusion matrix analysis.</p>
<pre class="r"><code>confusionMatrix(predRandomForests,testing$classe)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2232   15    0    0    0
##          B    0 1495   15    0    0
##          C    0    8 1349   21    2
##          D    0    0    4 1263    4
##          E    0    0    0    2 1436
## 
## Overall Statistics
##                                           
##                Accuracy : 0.991           
##                  95% CI : (0.9886, 0.9929)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9886          
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   0.9848   0.9861   0.9821   0.9958
## Specificity            0.9973   0.9976   0.9952   0.9988   0.9997
## Pos Pred Value         0.9933   0.9901   0.9775   0.9937   0.9986
## Neg Pred Value         1.0000   0.9964   0.9971   0.9965   0.9991
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2845   0.1905   0.1719   0.1610   0.1830
## Detection Prevalence   0.2864   0.1925   0.1759   0.1620   0.1833
## Balanced Accuracy      0.9987   0.9912   0.9907   0.9904   0.9978</code></pre>
</div>
<div id="quiz-dataset-predictions" class="section level2">
<h2>Quiz Dataset Predictions</h2>
<pre class="r"><code># LOAD QUIZ TESTING DATASET
quizTestingDF &lt;- read.csv(url(testingFileUrl), na.strings=naStringList, header=TRUE)

# SUBSET COLUMNS OF QUIZ DATASET FROM THE COLUMNS REDUCED IN MODEL-DF
quiz &lt;- quizTestingDF[, which(names(quizTestingDF) %in% colnames(modelDF))]
dim(quiz)</code></pre>
<pre><code>## [1] 20 39</code></pre>
<p><strong>Notably, there is no “classe” column in this dataset. We’ll just predict based on the other 30+ fields below.</strong></p>
<pre class="r"><code># PERFORM PREDICTIONS ON QUIZ TESTING DATASET
predict(modelRandomForests, quiz)</code></pre>
<pre><code>##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
##  B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
## Levels: A B C D E</code></pre>
<hr />
<div id="notes" class="section level3">
<h3>NOTES:</h3>
<p>To see smallwesley’s ML Project’s Prototype WIP (Work in Progress), to which many more experiement were run before this Knitr RMD file was created see:</p>
<p><a href="ml_project_prototype_wip.R" class="uri">ml_project_prototype_wip.R</a></p>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
